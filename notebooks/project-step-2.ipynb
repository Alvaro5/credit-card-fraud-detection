{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d60571",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# add src to path so we can import our data module\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(os.path.join(project_root, \"src\"))\n",
    "\n",
    "from data.load_data import download_creditcard_data, load_creditcard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ca44d",
   "metadata": {},
   "source": [
    "# Project step 2: Grid search and ensembles on credit card fraud\n",
    "\n",
    "In this notebook we apply grid search to our baseline models and we build ensemble models.\n",
    "We work on the same credit card fraud dataset as in project step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649f114",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# we download the data (if already downloaded this does nothing important)\n",
    "download_creditcard_data()\n",
    "df = load_creditcard_df()\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42,)\n",
    "\n",
    "# we check class balance on train and test\n",
    "print(\"Train class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5761c56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# we scale only Time and Amount and keep PCA components as they are\n",
    "numeric_to_scale = [\"Time\", \"Amount\"]\n",
    "other_features = [col for col in X.columns if col not in numeric_to_scale + [\"Class\"]]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"scale_time_amount\", StandardScaler(), numeric_to_scale),\n",
    "        (\"pass_others\", \"passthrough\", other_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3b5ec",
   "metadata": {},
   "source": [
    "## 1. Grid search on baseline models\n",
    "\n",
    "We tune two baseline models:\n",
    "- a Decision Tree with class weights for imbalance\n",
    "- a Logistic Regression with class weights\n",
    "\n",
    "We use F1 score for the fraud class as the main objective in the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c023bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
