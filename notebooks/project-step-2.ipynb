{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d60571",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     28\u001B[39m project_root = os.path.abspath(os.path.join(os.getcwd(), \u001B[33m\"\u001B[39m\u001B[33m..\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     29\u001B[39m sys.path.append(os.path.join(project_root, \u001B[33m\"\u001B[39m\u001B[33msrc\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mdata\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mload_data\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m download_creditcard_data, load_creditcard_df\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\leoma\\Documents\\ESILV\\A4 S1\\Machine Learning\\projet\\credit-card-fraud-detection\\src\\data\\load_data.py:3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mos\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkaggle\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mapi\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mkaggle_api_extended\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m KaggleApi\n\u001B[32m      5\u001B[39m PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(\u001B[34m__file__\u001B[39m), \u001B[33m\"\u001B[39m\u001B[33m..\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m..\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m      7\u001B[39m DATA_DIR = os.path.join(PROJECT_ROOT, \u001B[33m\"\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mraw\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'kaggle'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# add src to path so we can import our data module\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(os.path.join(project_root, \"src\"))\n",
    "\n",
    "from data.load_data import download_creditcard_data, load_creditcard_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ca44d",
   "metadata": {},
   "source": [
    "# Project step 2: Grid search and ensembles on credit card fraud\n",
    "\n",
    "In this notebook we apply grid search to our baseline models and we build ensemble models.\n",
    "We work on the same credit card fraud dataset as in project step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d649f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we download the data (if already downloaded this does nothing important)\n",
    "download_creditcard_data()\n",
    "df = load_creditcard_df()\n",
    "\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42,)\n",
    "\n",
    "# we check class balance on train and test\n",
    "print(\"Train class distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest class distribution:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5761c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we scale only Time and Amount and keep PCA components as they are\n",
    "numeric_to_scale = [\"Time\", \"Amount\"]\n",
    "other_features = [col for col in X.columns if col not in numeric_to_scale + [\"Class\"]]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"scale_time_amount\", StandardScaler(), numeric_to_scale),\n",
    "        (\"pass_others\", \"passthrough\", other_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f3b5ec",
   "metadata": {},
   "source": [
    "## 1. Grid search on baseline models\n",
    "\n",
    "We tune two baseline models:\n",
    "- a Decision Tree with class weights for imbalance\n",
    "- a Logistic Regression with class weights\n",
    "\n",
    "We use F1 score for the fraud class as the main objective in the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c023bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for decision tree\n",
    "dt_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", DecisionTreeClassifier(class_weight=\"balanced\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_dt = {\n",
    "    \"model__criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"model__max_depth\": [3, 5, 7, 9, None],\n",
    "    \"model__min_samples_split\": [2, 5, 10],\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(\n",
    "    estimator=dt_pipe,\n",
    "    param_grid=param_grid_dt,\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Decision Tree params:\")\n",
    "print(grid_dt.best_params_)\n",
    "print(f\"Best CV F1 score: {grid_dt.best_score_:.4f}\")\n",
    "\n",
    "best_dt = grid_dt.best_estimator_\n",
    "\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "y_proba_dt = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nDecision Tree classification report (test):\")\n",
    "print(classification_report(y_test, y_pred_dt, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682038f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Grid search for Logistic Regression\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m lr_pipe = \u001B[43mPipeline\u001B[49m(\n\u001B[32m      3\u001B[39m     steps=[\n\u001B[32m      4\u001B[39m         (\u001B[33m\"\u001B[39m\u001B[33mpreprocess\u001B[39m\u001B[33m\"\u001B[39m, preprocessor),\n\u001B[32m      5\u001B[39m         (\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m, LogisticRegression(class_weight=\u001B[33m\"\u001B[39m\u001B[33mbalanced\u001B[39m\u001B[33m\"\u001B[39m, max_iter=\u001B[32m1000\u001B[39m)),\n\u001B[32m      6\u001B[39m     ]\n\u001B[32m      7\u001B[39m )\n\u001B[32m      9\u001B[39m param_grid_lr = {\n\u001B[32m     10\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodel__C\u001B[39m\u001B[33m\"\u001B[39m: [\u001B[32m0.01\u001B[39m, \u001B[32m0.1\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m10\u001B[39m],\n\u001B[32m     11\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodel__penalty\u001B[39m\u001B[33m\"\u001B[39m: [\u001B[33m\"\u001B[39m\u001B[33ml2\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     12\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodel__solver\u001B[39m\u001B[33m\"\u001B[39m: [\u001B[33m\"\u001B[39m\u001B[33mliblinear\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mlbfgs\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     13\u001B[39m }\n\u001B[32m     15\u001B[39m grid_lr = GridSearchCV(\n\u001B[32m     16\u001B[39m     estimator=lr_pipe,\n\u001B[32m     17\u001B[39m     param_grid=param_grid_lr,\n\u001B[32m   (...)\u001B[39m\u001B[32m     21\u001B[39m     verbose=\u001B[32m1\u001B[39m,\n\u001B[32m     22\u001B[39m )\n",
      "\u001B[31mNameError\u001B[39m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Grid search for Logistic Regression\n",
    "lr_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", LogisticRegression(class_weight=\"balanced\", max_iter=1000)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_lr = {\n",
    "    \"model__C\": [0.01, 0.1, 1, 10],\n",
    "    \"model__penalty\": [\"l2\"],\n",
    "    \"model__solver\": [\"liblinear\", \"lbfgs\"],\n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    estimator=lr_pipe,\n",
    "    param_grid=param_grid_lr,\n",
    "    scoring=\"f1\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression params:\")\n",
    "print(grid_lr.best_params_)\n",
    "print(f\"Best CV F1 score: {grid_lr.best_score_:.4f}\")\n",
    "\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "y_pred_lr = best_lr.predict(X_test)\n",
    "y_proba_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nLogistic Regression classification report (test):\")\n",
    "print(classification_report(y_test, y_pred_lr, digits=4))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Ensemble models: Bagging and Voting\n",
    "\n",
    "We now build:\n",
    "- a Bagging ensemble based on a Decision Tree\n",
    "- a Voting ensemble that combines the tuned Decision Tree and the tuned Logistic Regression\n",
    "\n",
    "We keep the same train and test sets as before."
   ],
   "id": "6ddd32f8763ede5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:16:44.122016Z",
     "start_time": "2025-11-14T18:16:44.105028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bag_dt_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\n",
    "            \"model\",\n",
    "            BaggingClassifier(\n",
    "                estimator=DecisionTreeClassifier(\n",
    "                    class_weight=\"balanced\",\n",
    "                    random_state=42,\n",
    "                ),\n",
    "                n_estimators=50,\n",
    "                max_samples=0.8,\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "bag_dt_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_bag = bag_dt_pipe.predict(X_test)\n",
    "y_proba_bag = bag_dt_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Bagging Decision Tree classification report (test):\")\n",
    "print(classification_report(y_test, y_pred_bag, digits=4))"
   ],
   "id": "adbe1038653db15c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m bag_dt_pipe = \u001B[43mPipeline\u001B[49m(\n\u001B[32m      2\u001B[39m     steps=[\n\u001B[32m      3\u001B[39m         (\u001B[33m\"\u001B[39m\u001B[33mpreprocess\u001B[39m\u001B[33m\"\u001B[39m, preprocessor),\n\u001B[32m      4\u001B[39m         (\n\u001B[32m      5\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      6\u001B[39m             BaggingClassifier(\n\u001B[32m      7\u001B[39m                 estimator=DecisionTreeClassifier(\n\u001B[32m      8\u001B[39m                     class_weight=\u001B[33m\"\u001B[39m\u001B[33mbalanced\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      9\u001B[39m                     random_state=\u001B[32m42\u001B[39m,\n\u001B[32m     10\u001B[39m                 ),\n\u001B[32m     11\u001B[39m                 n_estimators=\u001B[32m50\u001B[39m,\n\u001B[32m     12\u001B[39m                 max_samples=\u001B[32m0.8\u001B[39m,\n\u001B[32m     13\u001B[39m                 n_jobs=-\u001B[32m1\u001B[39m,\n\u001B[32m     14\u001B[39m                 random_state=\u001B[32m42\u001B[39m,\n\u001B[32m     15\u001B[39m             ),\n\u001B[32m     16\u001B[39m         ),\n\u001B[32m     17\u001B[39m     ]\n\u001B[32m     18\u001B[39m )\n\u001B[32m     20\u001B[39m bag_dt_pipe.fit(X_train, y_train)\n\u001B[32m     22\u001B[39m y_pred_bag = bag_dt_pipe.predict(X_test)\n",
      "\u001B[31mNameError\u001B[39m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:16:51.110862Z",
     "start_time": "2025-11-14T18:16:51.092834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we build a VotingClassifier from the best pipelines\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"dt\", best_dt),\n",
    "        (\"lr\", best_lr),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_vote = voting_clf.predict(X_test)\n",
    "y_proba_vote = voting_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Voting ensemble classification report (test):\")\n",
    "print(classification_report(y_test, y_pred_vote, digits=4))"
   ],
   "id": "b6509bba8adb40b8",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VotingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# we build a VotingClassifier from the best pipelines\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m voting_clf = \u001B[43mVotingClassifier\u001B[49m(\n\u001B[32m      3\u001B[39m     estimators=[\n\u001B[32m      4\u001B[39m         (\u001B[33m\"\u001B[39m\u001B[33mdt\u001B[39m\u001B[33m\"\u001B[39m, best_dt),\n\u001B[32m      5\u001B[39m         (\u001B[33m\"\u001B[39m\u001B[33mlr\u001B[39m\u001B[33m\"\u001B[39m, best_lr),\n\u001B[32m      6\u001B[39m     ],\n\u001B[32m      7\u001B[39m     voting=\u001B[33m\"\u001B[39m\u001B[33msoft\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      8\u001B[39m )\n\u001B[32m     10\u001B[39m voting_clf.fit(X_train, y_train)\n\u001B[32m     12\u001B[39m y_pred_vote = voting_clf.predict(X_test)\n",
      "\u001B[31mNameError\u001B[39m: name 'VotingClassifier' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T18:17:02.523389Z",
     "start_time": "2025-11-14T18:17:02.505170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(y_true, y_pred, y_proba, name):\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "results.append(compute_metrics(y_test, y_pred_dt, y_proba_dt, \"DecisionTree (tuned)\"))\n",
    "results.append(compute_metrics(y_test, y_pred_lr, y_proba_lr, \"LogisticRegression (tuned)\"))\n",
    "results.append(compute_metrics(y_test, y_pred_bag, y_proba_bag, \"Bagging DT\"))\n",
    "results.append(compute_metrics(y_test, y_pred_vote, y_proba_vote, \"Voting (DT + LR)\"))\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ],
   "id": "c1888bbf0aa50827",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 13\u001B[39m\n\u001B[32m      2\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m      3\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: name,\n\u001B[32m      4\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m\"\u001B[39m: accuracy_score(y_true, y_pred),\n\u001B[32m   (...)\u001B[39m\u001B[32m      8\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mroc_auc\u001B[39m\u001B[33m\"\u001B[39m: roc_auc_score(y_true, y_proba),\n\u001B[32m      9\u001B[39m     }\n\u001B[32m     11\u001B[39m results = []\n\u001B[32m---> \u001B[39m\u001B[32m13\u001B[39m results.append(compute_metrics(\u001B[43my_test\u001B[49m, y_pred_dt, y_proba_dt, \u001B[33m\"\u001B[39m\u001B[33mDecisionTree (tuned)\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     14\u001B[39m results.append(compute_metrics(y_test, y_pred_lr, y_proba_lr, \u001B[33m\"\u001B[39m\u001B[33mLogisticRegression (tuned)\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m     15\u001B[39m results.append(compute_metrics(y_test, y_pred_bag, y_proba_bag, \u001B[33m\"\u001B[39m\u001B[33mBagging DT\u001B[39m\u001B[33m\"\u001B[39m))\n",
      "\u001B[31mNameError\u001B[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "321bf2ea39a1d53f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
